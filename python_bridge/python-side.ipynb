{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rust_bridge_pm_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import polars\n",
    "import rust_bridge_pm_py\n",
    "xes_path = \"/home/aarkue/doc/sciebo/alpha-revisit/Road_Traffic_Fine_Management_Process.xes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate huge event log (on Python side, but structs reside in Rust!)\n",
    "log = rust_bridge_pm_py.native.PyBridgeEventLog()\n",
    "for i in range(200000):\n",
    "  trace = rust_bridge_pm_py.native.PyBridgeTrace(\"Trace \" + str(i))\n",
    "  for j in range(15):\n",
    "    event = rust_bridge_pm_py.native.PyBridgeEvent({\"concept:name\": \"Activity \" + str(j)})\n",
    "    trace.insert_event(j,event)\n",
    "  log.insert_trace(i,trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = 0\n",
    "all_events_with_same_timestamp_in_case = 0 \n",
    "for g,r in log_df.groupby([\"case:concept:name\"]):\n",
    "  events_with_same_timestamp_in_case = r.shape[0] - len(r['time:timestamp'].unique())\n",
    "  all_events += r.shape[0]\n",
    "  all_events_with_same_timestamp_in_case += events_with_same_timestamp_in_case\n",
    "  assert events_with_same_timestamp_in_case >= 0 \n",
    "  # print(events_with_same_timestamp_in_case)\n",
    "print(all_events_with_same_timestamp_in_case/all_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read some event log\n",
    "log_df = pm4py.read_xes(xes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_log = rust_bridge_pm_py.native.import_xes(xes_path).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "net,im,fm = pm4py.discover_petri_net_inductive(res_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm4py.view_petri_net(net,im,fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rust_bridge_pm_py import petri_net\n",
    "trans_net = petri_net.petrinet_to_dict(net,im,[fm])\n",
    "res_net_json = rust_bridge_pm_py.native.test_petrinet(json.dumps(trans_net))\n",
    "res_net =  petri_net.dict_to_petrinet(json.loads(res_net_json))\n",
    "pm4py.view_petri_net(*res_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from pm4py.objects.petri_net.obj import PetriNet, Marking\n",
    "\n",
    "# Checks if two Accepting Petri Nets _could_ be equal (syntactically)\n",
    "# Best-effort check, does not compute full isomorphism between nets\n",
    "# Partly ignores silent transitions, so use with caution\n",
    "def pns_could_be_equal(a: Tuple[PetriNet,Marking,Marking], b: Tuple[PetriNet,Marking,Marking]):\n",
    "  failures_reasons = []\n",
    "  if len(a[0].transitions) != len(b[0].transitions):\n",
    "    failures_reasons.append(f\"Different number of transitions: {len(a[0].transitions)} != {len(b[0].transitions) }\")\n",
    "  if len(a[0].places) != len(b[0].places):\n",
    "    failures_reasons.append(f\"Different number of places: {len(a[0].places)} != {len(b[0].places) }\")\n",
    "  if len(a[0].arcs) != len(b[0].arcs):\n",
    "    failures_reasons.append(f\"Different number of arcs: {len(a[0].arcs)} != {len(b[0].arcs) }\")\n",
    "  transition_labels_a = [str(t.label) for t in a[0].transitions]\n",
    "  transition_labels_b = [str(t.label) for t in b[0].transitions]\n",
    "  if sorted(transition_labels_a) != sorted(transition_labels_b):\n",
    "    failures_reasons.append(f\"Transitions labels are not equal {list(sorted(transition_labels_a))} != {list(sorted(transition_labels_a))}\")\n",
    "  def extract_place_candidates(pn: PetriNet):\n",
    "    candidates = {p: (set(),set()) for p in pn.places}\n",
    "    for arc in pn.arcs:\n",
    "      if type(arc.source) == PetriNet.Place:\n",
    "        candidates[arc.source][0].add(str(arc.target.label))\n",
    "      elif type(arc.source) == PetriNet.Transition:\n",
    "        candidates[arc.target][1].add(str(arc.source.label))\n",
    "    return {(frozenset(in_trans),frozenset(out_trans)) for (in_trans,out_trans) in candidates.values()}\n",
    "  place_candidates_a = extract_place_candidates(a[0])\n",
    "  place_candidates_b = extract_place_candidates(b[0])\n",
    "  if place_candidates_a != place_candidates_b:\n",
    "    failures_reasons.append(f\"Different place candidates: {place_candidates_a} != {place_candidates_b}\")\n",
    "  if sorted(list(a[1].values())) != sorted(list(b[1].values())):\n",
    "    failures_reasons.append(f\"Initial Markings do not match: {a[1]} != {b[1]}\")\n",
    "  if sorted(list(a[2].values())) != sorted(list(b[2].values())):\n",
    "    failures_reasons.append(f\"Final Markings do not match: {a[2]} != {b[2]}\")\n",
    "  for reason in failures_reasons:\n",
    "    print(reason)\n",
    "  return len(failures_reasons) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pns_could_be_equal((net,im,fm),res_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convert DF log to PyBridgeEventLog Wrapper and then add start/end acts.\n",
    "# Result is again a PyBridgeEventLog Wrapper \n",
    "# Performance: Okay for smallish/normal logs but poor for very large ones\n",
    "res_log = rust_bridge_pm_py.native.test_bridge_log(pm4py_log_to_bridge_log(log_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: Do not require Polar dependency on python side, by exporting JSON with pandas\n",
    "# and then importing it using Polar on the Rust side\n",
    "log = rust_bridge_pm_py.native.test_df_pandas(log_df.to_json(orient=\"records\"),\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as directly above, but using CSV:\n",
    "log = rust_bridge_pm_py.native.test_df_pandas(log_df.to_csv(),\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: Do DataFrame -> Wrapper conversion on Rust side (+ in parallel)\n",
    "# For that, polars is used (because of the first-class Rust support)\n",
    "# First, convert log (pandas) DF to polars DF and then convert it to PyBridgeEventLog Wrapper in Rust, return Result \n",
    "# Performance: Pretty good :) \n",
    "log = rust_bridge_pm_py.native.polars_df_to_log(polars.from_pandas(log_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create huge event log & process it in Rust\n",
    "# For conversion, use json bytes (using orjson library)\n",
    "# Not great performance...\n",
    "# Total: 15308.481216430664ms; Json Dump & Log Re-construction from Dict takes the most time\n",
    "# This prompted the experimentation with PyBridgeEventLog Wrapper, living in Rust\n",
    "l = rust_bridge_pm_py.event_log.py_test_event_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python-side PyBridgeEventLog construction: Slow!\n",
    "import pandas as pd\n",
    "def pm4py_log_to_bridge_log(df: pd.DataFrame):\n",
    "  log = rust_bridge_pm_py.native.PyBridgeEventLog()\n",
    "  for trace_id,a in df.groupby(['case:concept:name']):\n",
    "    trace = rust_bridge_pm_py.native.PyBridgeTrace(str(trace_id))\n",
    "    for (label,series) in a.iterrows():\n",
    "      event = rust_bridge_pm_py.native.PyBridgeEvent({k: str(v) for (k,v) in series.to_dict().items()})\n",
    "      trace.append_event(event)\n",
    "    log.append_trace(trace)\n",
    "  return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample call: Add artificial start and end activities to every trace\n",
    "res_log = rust_bridge_pm_py.native.test_bridge_log(log)\n",
    "assert res_log.traces[0].events[0].attributes.get(\"concept:name\") == \"__START__\"\n",
    "assert res_log.traces[0].events[-1].attributes.get(\"concept:name\") == \"__END__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['arcs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.petri_net.obj import PetriNet\n",
    "\n",
    "\n",
    "def petrinet_to_dict(net: PetriNet) -> dict:\n",
    "    places = {p.name: {\"id\": p.name} for p in net.places}\n",
    "    transitions = {t.name: {\"id\": t.name, \"label\": t.label} for t in net.transitions}\n",
    "    arcs = [\n",
    "        {\n",
    "            \"from_to\": {\n",
    "                \"type\": \"PlaceTransition\"\n",
    "                if type(arc.source) == PetriNet.Place\n",
    "                else \"TransitionPlace\",\n",
    "                \"nodes\": [arc.source.name, arc.target.name],\n",
    "            },\n",
    "            \"weight\": arc.weight,\n",
    "        }\n",
    "        for arc in net.arcs\n",
    "    ]\n",
    "    return {\"places\": places, \"transitions\": transitions, \"arcs\": arcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petrinet_to_dict(dict_to_petrinet(res)) == res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.petri_net.obj import PetriNet\n",
    "\n",
    "\n",
    "def dict_to_petrinet(net_dict) -> PetriNet:\n",
    "    places = {p[\"id\"]: PetriNet.Place(p[\"id\"]) for p in net_dict[\"places\"].values()}\n",
    "    transitions = {\n",
    "        t[\"id\"]: PetriNet.Transition(t[\"id\"], t[\"label\"])\n",
    "        for t in net_dict[\"transitions\"].values()\n",
    "    }\n",
    "\n",
    "    def get_arc_for(arc_dict):\n",
    "        if arc_dict[\"from_to\"][\"type\"] == \"PlaceTransition\":\n",
    "            fr = places.get(arc_dict[\"from_to\"][\"nodes\"][0])\n",
    "            to = transitions.get(arc_dict[\"from_to\"][\"nodes\"][1])\n",
    "        else:\n",
    "            fr = transitions.get(arc_dict[\"from_to\"][\"nodes\"][0])\n",
    "            to = places.get(arc_dict[\"from_to\"][\"nodes\"][1])\n",
    "        return PetriNet.Arc(fr, to, arc_dict[\"weight\"])\n",
    "\n",
    "    arcs = [get_arc_for(arc_dict) for arc_dict in net_dict[\"arcs\"]]\n",
    "    net = PetriNet(None, places.values(), transitions.values(), arcs)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm4py.view_petri_net(dict_to_petrinet(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rust_bridge_pm_py\n",
    "import json\n",
    "res = json.loads(rust_bridge_pm_py.native.test_petrinet())\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform PyBridgeEventLog to dict (only keeping activity names + case id)\n",
    "traces = []\n",
    "for trace in log.traces:\n",
    "  events = []\n",
    "  for event in trace.events:\n",
    "    events.append({\"concept:name\": event.attributes.get(\"concept:name\")})\n",
    "  traces.append({\"case:concept:name\": trace.attributes.get(\"case:concept:name\"),\"events\": events})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
